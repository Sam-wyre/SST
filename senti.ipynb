{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to content and style images\n",
    "sentiment_image_path = './Sentiment_images/moody/download.jpeg'\n",
    "content_image_path = './Content_images/Fsee5IYaAAAMc-5.jpeg'\n",
    "\n",
    "def preprocess_data(path):\n",
    "    img = load_img(\n",
    "        path, target_size=(img_nrows, img_ncols)\n",
    "    )\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return tf.convert_to_tensor(img)\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "\n",
    "width, height = load_img(sentiment_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)\n",
    "\n",
    "\"\"\" The keras method of preprocessing images\"\"\"\n",
    "senti_image = preprocess_data(sentiment_image_path)\n",
    "content_image = preprocess_data(content_image_path)\n",
    "\n",
    "senti_layers = ['block3_conv1', 'block4_conv1']\n",
    "content_layer ='block5_conv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights of the different loss components\n",
    "total_variation_weight = 1.0\n",
    "senti_weight = 1e-5\n",
    "content_weight = 1.0\n",
    "\n",
    "result_name = \"./senti/sentiment_gen\"\n",
    "\n",
    "# Build a VGG19 model loaded with pre-trained ImageNet weights\n",
    "model = tf.keras.applications.VGG19(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "# Set up a model that returns the activation values for every layer in\n",
    "# VGG19 (as a dict).\n",
    "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSEsenti_loss(senti_features, target_features):\n",
    "    loss = tf.reduce_mean(tf.square(senti_features - target_features))\n",
    "    return loss\n",
    "\n",
    "def similarity_basedloss(sentiment_features, transferred_features):\n",
    "    # Compute the cosine similarity between sentiment features and transferred features\n",
    "    sentiment_norm = tf.norm(sentiment_features, axis=1, keepdims=True)\n",
    "    transferred_norm = tf.norm(transferred_features, axis=1, keepdims=True)\n",
    "    cosine_similarity = tf.reduce_sum(sentiment_features * transferred_features, axis=1) / (sentiment_norm * transferred_norm)\n",
    "    \n",
    "    # Compute the sentiment loss as 1 - cosine similarity\n",
    "    loss = 1 - cosine_similarity\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def content_loss(base, target):\n",
    "    return tf.reduce_sum(tf.square(target - base))\n",
    "\n",
    "# total variation loss,\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = tf.square(\n",
    "        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :]\n",
    "    )\n",
    "    b = tf.square(\n",
    "        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :]\n",
    "    )\n",
    "    return tf.reduce_sum(tf.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(content_image, senti_image, target_image):\n",
    "    input_tensor = tf.concat(\n",
    "        [content_image, senti_image, target_image], axis=0\n",
    "    )\n",
    "    features = feature_extractor(input_tensor)\n",
    "\n",
    "    # Initialize the loss\n",
    "    loss = tf.zeros(shape=())\n",
    "\n",
    "    # Add content loss\n",
    "    layer_features = features[content_layer]\n",
    "    content_image_features = layer_features[0, :, :, :]\n",
    "    target_features = layer_features[2, :, :, :]\n",
    "    loss = loss + content_weight * content_loss(\n",
    "        content_image_features, target_features\n",
    "    )\n",
    "    # Add style loss\n",
    "    for layer_name in senti_layers:\n",
    "        layer_features = features[layer_name]\n",
    "        senti_features = layer_features[1, :, :, :]\n",
    "        target_features = layer_features[2, :, :, :]\n",
    "        sl = MSEsenti_loss(senti_features, target_features)\n",
    "        loss += (senti_weight / len(senti_layers)) * sl\n",
    "\n",
    "    # Add total variation loss\n",
    "    loss += total_variation_weight * total_variation_loss(target_image)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss_and_gradients(content_image, senti_image, target_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(content_image, senti_image, target_image)\n",
    "    grads = tape.gradient(loss, target_image)\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [03:06<09:01,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50: loss=1668052224.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [06:24<06:49,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: loss=1194964352.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [09:43<03:36,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150: loss=1405720448.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [13:05<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200: loss=1527742720.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96)\n",
    ")\n",
    "target_image = tf.Variable(preprocess_data(content_image_path))\n",
    "senti_resized = tf.image.resize(senti_image, (405, 512))\n",
    "\n",
    "iter = 200\n",
    "for i in tqdm(range(1, iter + 1)):\n",
    "    loss, grads = compute_loss_and_gradients(\n",
    "        content_image, senti_image, target_image,\n",
    "    )\n",
    "    optimizer.apply_gradients([(grads, target_image)])\n",
    "\n",
    "    # save image after every 1000 steps\n",
    "    if i % 50 == 0:\n",
    "        print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
    "        img = deprocess_image(target_image.numpy())\n",
    "        fname = result_name + \"_at_iteration_%d.png\" % i\n",
    "        tf.keras.preprocessing.image.save_img(fname, img)\n",
    "        # display(Image(fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
